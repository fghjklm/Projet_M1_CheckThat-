##############################################################################################
Article lu : DWReCO at CheckThat! 2023: Enhancing Subjectivity
Detection through Style-based Data Sampling

Auteur de la synthèse : Oleiwan Joe

Lien : https://ceur-ws.org/Vol-3497/paper-026.pdf


informations extraites:
-(0)	: Edition 2023: Equilibration de classes en utilisant des ressources d'entrainement 		supplémentaires générées avec des modèles de GPT-3 avec des 
		des prompts de style différents d'une checkliste basé sur la perspective journalistique.
-(1)	: Déséquilibrage de données intra-classes: obj >>>> subj
-(1)	: La subjectivité en tâches journalistiques est différente de la subjectivité dans les autres tâches.
-(1)	: Trois langues d'experimentation pour cette équipe: anglais, turque, allemand.
-(1)	: Cette équipe démontre que l'utilisation de différents styles subjectifs = 
		performance++ en détéction de subjectivité.
-(2.2)	: Ratio obtenu environ 50 50 entre données subj et obj.
-(2.2)	: Comparaison entre deux modèles GPT-3: text-davinci-003, gpt-3.5-turbo. les perfs 
		dépendent de la tâche donnée
-(4)	: La checkliste de subjectivité est construite avec différents indicateurs que les 
		journalistes utilisent pour détécter la subjéctivité
-(4.1)	: A cause de la vaste def de la subj et des réponses biaisées des modèles GPT-3, il 
		faut faire attention aux texte généré qu'il soit adéquat au style journalistique attendu.
-(4.2)	: Template de style d'écriture pour anglais, essayé avec les autres langues = failed; 		  patron de style crée pour chaque langue par conséquent
-(4.3)	: Méthode de génération et échantillonage:    
			Calcul de la différence entre le nombre d'échantillons subjectifs et objectifs pour chaque langue du jeu de données d'entraînement, suivi d'une sélection aléatoire d'échantillons objectifs en fonction de cette différence pour chaque style dans la liste de vérification.

   			Sélection d'échantillons de la distribution de classe subjective pour le style normal, définis comme des échantillons subjectifs qui ne sont pas exagérément orientés vers une autre catégorie de style spécifique. Ceci est utilisé comme base de comparaison pour les autres styles dans la liste de vérification.

    		Génération de nouveaux textes à partir des échantillons sélectionnés en utilisant les modèles OpenAI GPT-3.
 -(4.4)	: Modèles entrainés : Roberta-base for anglais
 							  German Bert for allemand
 							  BERTurk for turque
-(5.1)	: Les résultats montrent que l'ajout d'échantillons basés sur le style améliore la 
		robustesse des modèles de transformateurs en anglais et en turc, mais n'a pas d'effet significatif sur les transformateurs en allemand.
		(generation de texte par text-davinci-003 ) pas de changement notables avec ChatGPT (3.5 turbo).
-(5.2)	: L'évaluation qualitative des textes générés par text-davinci-003 et Chat-GPT en anglais, allemand et turc montre que l'anglais a les phrases les plus plausibles. Le modèle 2 excelle en qualité (Q1) mais tend à exagérer les styles, affectant la naturalité (Q2), surtout en anglais et allemand. En turc, le modèle 2 est supérieur en grammaire et sens, mais les textes ne sont pas toujours parfaits. Un problème commun est l'utilisation répétitive d'altérations de style par les modèles, notamment l'ajout de pronoms dans le style subjectif.
-(6)	: Conclusion: style based data augmentation > paraphraser du texte.

##############################################################################################

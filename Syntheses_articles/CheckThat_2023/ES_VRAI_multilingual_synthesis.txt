Article lu: ES-VRAI at CheckThat! 2023: Enhancing Model Performance for Subjectivity Detection through Multilingual Data Aggregation
Lien: https://ceur-ws.org/Vol-3497/paper-037.pdf
Auteur de la synthèse: Mortimer MEUNIER

- Résultats :
Multilingue: 4 +

- Modèles :
BERT-Multilingual
XLM-RoBERTa

tests sur chaque modèle avec: dataset de base / dataset+upsampling / dataset + downsampling.
Meilleurs résultats avec BERT-Multilingual sur dataset + upsampling


- Fine-tuning :



- Traitement des données :
Deux tests différents: Upsampling (de la classe minoritaire) et downsampling (de la classe majoritaire).

data aggregation: ils ont réuni tous les dataSet en un seul multilingue pour augmenter la taille du set d'apprentissage.



- Problèmes rencontrés :
imbalance


- Critiques:
4ème en multilingue, aucune info sur chaque langue séparément.
aucun détail sur les méthodes utilisés -< à part l'idée du down et upsampling on ne peut pas utiliser ceci de manière brute